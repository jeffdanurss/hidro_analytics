import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de estilo
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 8)

def load_precip_level_data():
    """Cargar datos de precipitaci√≥n y nivel"""
    try:
        precip_papallacta = pd.read_csv('precipitacion_papallacta.csv')
        nivel_papallacta = pd.read_csv('nivel_papallacta.csv')
        precip_quijos = pd.read_csv('precipitacion_quijos.csv')
        nivel_quijos = pd.read_csv('nivel_quijos.csv')
        
        print("‚úÖ Datos cargados exitosamente")
        return precip_papallacta, nivel_papallacta, precip_quijos, nivel_quijos
    except Exception as e:
        print(f"‚ùå Error cargando datos: {e}")
        return None, None, None, None

def prepare_precip_level_data(precip_data, nivel_data, station_name):
    """Preparar datos de precipitaci√≥n y nivel para una estaci√≥n"""
    print(f"\nüìç PROCESANDO DATOS: {station_name}")
    
    # Procesar precipitaci√≥n - suma total por registro
    precip_cols = [col for col in precip_data.columns if col != 'Fecha']
    if precip_cols:
        precip_data['Precip_Total'] = precip_data[precip_cols].sum(axis=1)
    else:
        precip_data['Precip_Total'] = precip_data.iloc[:, 1:].sum(axis=1)
    
    # Procesar nivel - promedio de todas las estaciones
    nivel_cols = [col for col in nivel_data.columns if col != 'Fecha']
    if nivel_cols:
        nivel_data['Nivel_Prom'] = nivel_data[nivel_cols].mean(axis=1)
    else:
        nivel_data['Nivel_Prom'] = nivel_data.iloc[:, 1:].mean(axis=1)
    
    # Alinear datos por fecha
    if 'Fecha' in precip_data.columns and 'Fecha' in nivel_data.columns:
        precip_data['Fecha'] = pd.to_datetime(precip_data['Fecha'])
        nivel_data['Fecha'] = pd.to_datetime(nivel_data['Fecha'])
        
        # Merge por fecha
        merged_data = pd.merge(precip_data[['Fecha', 'Precip_Total']], 
                              nivel_data[['Fecha', 'Nivel_Prom']], 
                              on='Fecha', how='inner')
    else:
        # Alinear por √≠ndice
        min_len = min(len(precip_data), len(nivel_data))
        merged_data = pd.DataFrame({
            'Precip_Total': precip_data['Precip_Total'].iloc[:min_len],
            'Nivel_Prom': nivel_data['Nivel_Prom'].iloc[:min_len]
        })
    
    # Eliminar valores NaN
    merged_data = merged_data.dropna()
    
    print(f"üìä Registros alineados: {len(merged_data)}")
    return merged_data

def analyze_precip_level_relationship(data, station_name):
    """Analizar relaci√≥n precipitaci√≥n-nivel"""
    print(f"\n{'='*60}")
    print(f"üìä AN√ÅLISIS PRECIPITACI√ìN-NIVEL: {station_name.upper()}")
    print(f"{'='*60}")
    
    if len(data) < 5:
        print("‚ö†Ô∏è  Insuficientes datos para an√°lisis")
        return None
    
    precip = data['Precip_Total']
    nivel = data['Nivel_Prom']
    
    # Correlaciones
    pearson_corr, pearson_p = stats.pearsonr(precip, nivel)
    spearman_corr, spearman_p = stats.spearmanr(precip, nivel)
    
    print(f"üìà REGISTROS ANALIZADOS: {len(data)}")
    print(f"üîó CORRELACI√ìN PEARSON: {pearson_corr:.3f} (p-value: {pearson_p:.4f})")
    print(f"üîó CORRELACI√ìN SPEARMAN: {spearman_corr:.3f} (p-value: {spearman_p:.4f})")
    
    # Interpretaci√≥n
    if pearson_p < 0.05:
        print("‚úÖ CORRELACI√ìN ESTAD√çSTICAMENTE SIGNIFICATIVA")
        if abs(pearson_corr) > 0.7:
            print("üéØ RELACI√ìN MUY FUERTE")
        elif abs(pearson_corr) > 0.5:
            print("üìä RELACI√ìN MODERADA-FUERTE")
        elif abs(pearson_corr) > 0.3:
            print("üìà RELACI√ìN MODERADA")
        else:
            print("üîÑ RELACI√ìN D√âBIL")
    else:
        print("‚ùå CORRELACI√ìN NO SIGNIFICATIVA ESTAD√çSTICAMENTE")
    
    # An√°lisis por cuartiles
    print(f"\nüìä AN√ÅLISIS POR CUARTILES:")
    precip_q1 = precip.quantile(0.25)
    precip_q2 = precip.quantile(0.50)
    precip_q3 = precip.quantile(0.75)
    
    nivel_q1 = nivel.quantile(0.25)
    nivel_q2 = nivel.quantile(0.50)
    nivel_q3 = nivel.quantile(0.75)
    
    print(f"   Precipitaci√≥n - Q1: {precip_q1:.2f}, Q2: {precip_q2:.2f}, Q3: {precip_q3:.2f}")
    print(f"   Nivel - Q1: {nivel_q1:.2f}, Q2: {nivel_q2:.2f}, Q3: {nivel_q3:.2f}")
    
    # Modelos de regresi√≥n
    results = {}
    
    # 1. Regresi√≥n lineal
    X_linear = precip.values.reshape(-1, 1)
    y_linear = nivel.values
    linear_model = LinearRegression().fit(X_linear, y_linear)
    linear_r2 = r2_score(y_linear, linear_model.predict(X_linear))
    linear_rmse = np.sqrt(mean_squared_error(y_linear, linear_model.predict(X_linear)))
    
    results['linear'] = {
        'model': linear_model,
        'r2': linear_r2,
        'rmse': linear_rmse,
        'equation': f"Nivel = {linear_model.coef_[0]:.4f} √ó Precip + {linear_model.intercept_:.2f}"
    }
    
    # 2. Regresi√≥n polin√≥mica (cuadr√°tica)
    poly_features = PolynomialFeatures(degree=2)
    X_poly = poly_features.fit_transform(precip.values.reshape(-1, 1))
    poly_model = LinearRegression().fit(X_poly, y_linear)
    poly_r2 = r2_score(y_linear, poly_model.predict(X_poly))
    poly_rmse = np.sqrt(mean_squared_error(y_linear, poly_model.predict(X_poly)))
    
    results['polynomial'] = {
        'model': poly_model,
        'poly_features': poly_features,
        'r2': poly_r2,
        'rmse': poly_rmse
    }
    
    # Mostrar resultados
    print(f"\nüìä MODELOS DE REGRESI√ìN:")
    print(f"   Lineal - R¬≤: {linear_r2:.3f}, RMSE: {linear_rmse:.2f}")
    print(f"   Ecuaci√≥n: {results['linear']['equation']}")
    print(f"   Polin√≥mica - R¬≤: {poly_r2:.3f}, RMSE: {poly_rmse:.2f}")
    
    # Estad√≠sticas descriptivas
    print(f"\nüìã ESTAD√çSTICAS DESCRIPTIVAS:")
    print(f"   Precipitaci√≥n - Media: {precip.mean():.2f}, Desv: {precip.std():.2f}")
    print(f"   Nivel - Media: {nivel.mean():.2f}, Desv: {nivel.std():.2f}")
    print(f"   Rango Precip: {precip.min():.2f} - {precip.max():.2f}")
    print(f"   Rango Nivel: {nivel.min():.2f} - {nivel.max():.2f}")
    
    return results

def create_precip_level_visualizations(data, station_name, results):
    """Crear visualizaciones del an√°lisis precipitaci√≥n-nivel"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'An√°lisis Precipitaci√≥n-Nivel: {station_name}', fontsize=16, fontweight='bold')
    
    precip = data['Precip_Total']
    nivel = data['Nivel_Prom']
    
    # 1. Diagrama de dispersi√≥n con regresi√≥n lineal
    axes[0, 0].scatter(precip, nivel, alpha=0.6, color='blue', s=50)
    axes[0, 0].set_xlabel('Precipitaci√≥n Total')
    axes[0, 0].set_ylabel('Nivel de Agua')
    axes[0, 0].set_title('Relaci√≥n Precipitaci√≥n-Nivel (Lineal)')
    axes[0, 0].grid(True, alpha=0.3)
    
    # L√≠nea de regresi√≥n lineal
    precip_sorted = np.sort(precip)
    linear_pred = results['linear']['model'].predict(precip_sorted.reshape(-1, 1))
    axes[0, 0].plot(precip_sorted, linear_pred, 'r-', linewidth=2, 
                    label=f'R¬≤ = {results["linear"]["r2"]:.3f}')
    axes[0, 0].legend()
    
    # 2. Diagrama de dispersi√≥n con regresi√≥n polin√≥mica
    axes[0, 1].scatter(precip, nivel, alpha=0.6, color='green', s=50)
    axes[0, 1].set_xlabel('Precipitaci√≥n Total')
    axes[0, 1].set_ylabel('Nivel de Agua')
    axes[0, 1].set_title('Relaci√≥n Precipitaci√≥n-Nivel (Polin√≥mica)')
    axes[0, 1].grid(True, alpha=0.3)
    
    # L√≠nea de regresi√≥n polin√≥mica
    precip_sorted = np.sort(precip)
    X_poly_sorted = results['polynomial']['poly_features'].transform(precip_sorted.reshape(-1, 1))
    poly_pred = results['polynomial']['model'].predict(X_poly_sorted)
    axes[0, 1].plot(precip_sorted, poly_pred, 'orange', linewidth=2,
                    label=f'R¬≤ = {results["polynomial"]["r2"]:.3f}')
    axes[0, 1].legend()
    
    # 3. Histogramas
    axes[1, 0].hist(precip, bins=20, alpha=0.7, color='lightblue', edgecolor='black')
    axes[1, 0].set_xlabel('Precipitaci√≥n Total')
    axes[1, 0].set_ylabel('Frecuencia')
    axes[1, 0].set_title('Distribuci√≥n de Precipitaci√≥n')
    axes[1, 0].grid(True, alpha=0.3)
    
    axes[1, 1].hist(nivel, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[1, 1].set_xlabel('Nivel de Agua')
    axes[1, 1].set_ylabel('Frecuencia')
    axes[1, 1].set_title('Distribuci√≥n de Nivel')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'precip_nivel_{station_name.lower().replace(" ", "_")}.png', 
                dpi=300, bbox_inches='tight')
    plt.show()

def analyze_lag_correlation(precip_data, nivel_data, station_name, max_lag=10):
    """Analizar correlaci√≥n con diferentes rezagos temporales"""
    print(f"\n{'='*60}")
    print(f"üìä AN√ÅLISIS DE REZAGOS TEMPORALES: {station_name.upper()}")
    print(f"{'='*60}")
    
    # Preparar datos
    precip = precip_data['Precip_Total']
    nivel = nivel_data['Nivel_Prom']
    
    min_len = min(len(precip), len(nivel))
    precip = precip.iloc[:min_len]
    nivel = nivel.iloc[:min_len]
    
    # Calcular correlaciones para diferentes rezagos
    lags = range(0, min(max_lag + 1, len(precip)//2))
    correlations = []
    
    for lag in lags:
        if lag == 0:
            corr, _ = stats.pearsonr(precip, nivel)
        else:
            corr, _ = stats.pearsonr(precip.iloc[:-lag], nivel.iloc[lag:])
        correlations.append(corr)
    
    # Encontrar mejor rezago
    best_lag = lags[np.argmax(correlations)]
    best_corr = max(correlations)
    
    print(f"üìà MEJOR CORRELACI√ìN ENCONTRADA:")
    print(f"   Rezago √≥ptimo: {best_lag} per√≠odo(s)")
    print(f"   Correlaci√≥n m√°xima: {best_corr:.3f}")
    
    # Visualizaci√≥n de rezagos
    plt.figure(figsize=(10, 6))
    plt.plot(lags, correlations, 'bo-', linewidth=2, markersize=8)
    plt.xlabel('Rezago (per√≠odos)')
    plt.ylabel('Correlaci√≥n')
    plt.title(f'Correlaci√≥n Precipitaci√≥n-Nivel vs Rezago - {station_name}')
    plt.grid(True, alpha=0.3)
    plt.axvline(x=best_lag, color='red', linestyle='--', alpha=0.7, 
                label=f'Mejor rezago: {best_lag}')
    plt.legend()
    plt.tight_layout()
    plt.savefig(f'rezagos_{station_name.lower().replace(" ", "_")}.png', 
                dpi=300, bbox_inches='tight')
    plt.show()
    
    return best_lag, best_corr

def main_precip_level_analysis():
    """Funci√≥n principal para an√°lisis precipitaci√≥n-nivel"""
    print("üåßÔ∏è AN√ÅLISIS DE RELACI√ìN PRECIPITACI√ìN-NIVEL")
    print("="*60)
    
    # Cargar datos
    precip_papallacta, nivel_papallacta, precip_quijos, nivel_quijos = load_precip_level_data()
    
    if precip_papallacta is None:
        return
    
    all_results = {}
    
    # An√°lisis Papallacta
    print("\n" + "="*80)
    data_papallacta = prepare_precip_level_data(precip_papallacta, nivel_papallacta, "Papallacta")
    if len(data_papallacta) > 0:
        results_papallacta = analyze_precip_level_relationship(data_papallacta, "Papallacta")
        if results_papallacta:
            create_precip_level_visualizations(data_papallacta, "Papallacta", results_papallacta)
            
            # An√°lisis de rezagos
            try:
                best_lag, best_corr = analyze_lag_correlation(
                    precip_papallacta[['Precip_Total']], 
                    nivel_papallacta[['Nivel_Prom']], 
                    "Papallacta"
                )
                results_papallacta['best_lag'] = best_lag
                results_papallacta['best_lag_corr'] = best_corr
            except:
                print("‚ö†Ô∏è  No se pudo calcular an√°lisis de rezagos para Papallacta")
            
            all_results['Papallacta'] = results_papallacta
    
    # An√°lisis Quijos
    print("\n" + "="*80)
    data_quijos = prepare_precip_level_data(precip_quijos, nivel_quijos, "Quijos")
    if len(data_quijos) > 0:
        results_quijos = analyze_precip_level_relationship(data_quijos, "Quijos")
        if results_quijos:
            create_precip_level_visualizations(data_quijos, "Quijos", results_quijos)
            
            # An√°lisis de rezagos
            try:
                best_lag, best_corr = analyze_lag_correlation(
                    precip_quijos[['Precip_Total']], 
                    nivel_quijos[['Nivel_Prom']], 
                    "Quijos"
                )
                results_quijos['best_lag'] = best_lag
                results_quijos['best_lag_corr'] = best_corr
            except:
                print("‚ö†Ô∏è  No se pudo calcular an√°lisis de rezagos para Quijos")
            
            all_results['Quijos'] = results_quijos
    
    # Resumen comparativo
    print(f"\n{'='*80}")
    print("üìã RESUMEN COMPARATIVO")
    print(f"{'='*80}")
    
    for station, results in all_results.items():
        if results:
            print(f"\nüìç {station}:")
            print(f"   Correlaci√≥n directa: {results['linear']['r2']:.3f}")
            print(f"   Correlaci√≥n polin√≥mica: {results['polynomial']['r2']:.3f}")
            if 'best_lag' in results:
                print(f"   Mejor rezago: {results['best_lag']} per√≠odos")
                print(f"   Correlaci√≥n con rezago: {results['best_lag_corr']:.3f}")
            
            if results['polynomial']['r2'] > results['linear']['r2']:
                print("   üéØ Modelo polin√≥mico m√°s adecuado")
            else:
                print("   üìä Modelo lineal m√°s adecuado")
    
    return all_results

# Ejecutar an√°lisis
if __name__ == "__main__":
    results = main_precip_level_analysis()
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import warnings
warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de estilo
plt.style.use('seaborn-v0_8')
plt.rcParams['figure.figsize'] = (12, 8)

def load_and_prepare_data():
    """Cargar y preparar los datos"""
    try:
        # Cargar datos
        precip_papallacta = pd.read_csv('precipitacion_papallacta.csv')
        precip_quijos = pd.read_csv('precipitacion_quijos.csv')
        caudal_papallacta = pd.read_csv('caudal_papallacta.csv')
        caudal_quijos = pd.read_csv('caudal_quijos.csv')
        
        print("âœ… Datos cargados exitosamente")
        return precip_papallacta, precip_quijos, caudal_papallacta, caudal_quijos
    except Exception as e:
        print(f"âŒ Error cargando datos: {e}")
        return None, None, None, None

def analyze_correlation_station(precip_data, caudal_data, station_name):
    """Analizar correlaciÃ³n para una estaciÃ³n especÃ­fica"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ANÃLISIS PRECIPITACIÃ“N-CAUDAL: {station_name.upper()}")
    print(f"{'='*60}")
    
    # Crear DataFrames para anÃ¡lisis
    precip_df = pd.DataFrame()
    caudal_df = pd.DataFrame()
    
    # Procesar datos de precipitaciÃ³n
    precip_cols = [col for col in precip_data.columns if col != 'Fecha']
    caudal_cols = [col for col in caudal_data.columns if col != 'Fecha']
    
    # Convertir fechas si existen
    if 'Fecha' in precip_data.columns:
        precip_data['Fecha'] = pd.to_datetime(precip_data['Fecha'])
    if 'Fecha' in caudal_data.columns:
        caudal_data['Fecha'] = pd.to_datetime(caudal_data['Fecha'])
    
    # Calcular precipitaciÃ³n total por registro
    if precip_cols:
        precip_data['Precip_Total'] = precip_data[precip_cols].sum(axis=1)
    else:
        precip_data['Precip_Total'] = precip_data.iloc[:, 1:].sum(axis=1) if len(precip_data.columns) > 1 else precip_data.iloc[:, 0]
    
    # Calcular caudal promedio por registro
    if caudal_cols:
        caudal_data['Caudal_Prom'] = caudal_data[caudal_cols].mean(axis=1)
    else:
        caudal_data['Caudal_Prom'] = caudal_data.iloc[:, 1:].mean(axis=1) if len(caudal_data.columns) > 1 else caudal_data.iloc[:, 0]
    
    # Alinear datos por fecha o Ã­ndice
    if 'Fecha' in precip_data.columns and 'Fecha' in caudal_data.columns:
        # Merge por fecha
        merged_data = pd.merge(precip_data[['Fecha', 'Precip_Total']], 
                              caudal_data[['Fecha', 'Caudal_Prom']], 
                              on='Fecha', how='inner')
    else:
        # Alinear por Ã­ndice comÃºn (mÃ­nimo registros)
        min_len = min(len(precip_data), len(caudal_data))
        merged_data = pd.DataFrame({
            'Precip_Total': precip_data['Precip_Total'].iloc[:min_len],
            'Caudal_Prom': caudal_data['Caudal_Prom'].iloc[:min_len]
        })
    
    # Eliminar valores NaN
    merged_data = merged_data.dropna()
    
    if len(merged_data) < 10:
        print("âš ï¸  Insuficientes datos para anÃ¡lisis significativo")
        return None
    
    # CÃ¡lculos estadÃ­sticos
    precip = merged_data['Precip_Total']
    caudal = merged_data['Caudal_Prom']
    
    # CorrelaciÃ³n de Pearson
    correlation, p_value = stats.pearsonr(precip, caudal)
    
    # CorrelaciÃ³n de Spearman (no paramÃ©trica)
    spearman_corr, spearman_p = stats.spearmanr(precip, caudal)
    
    print(f"ğŸ“ˆ REGISTROS ANALIZADOS: {len(merged_data)}")
    print(f"ğŸ”— CORRELACIÃ“N PEARSON: {correlation:.3f} (p-value: {p_value:.4f})")
    print(f"ğŸ”— CORRELACIÃ“N SPEARMAN: {spearman_corr:.3f} (p-value: {spearman_p:.4f})")
    
    # InterpretaciÃ³n
    if p_value < 0.05:
        print("âœ… CORRELACIÃ“N ESTADÃSTICAMENTE SIGNIFICATIVA")
        if correlation > 0.7:
            print("ğŸ¯ RELACIÃ“N MUY FUERTE POSITIVA")
        elif correlation > 0.5:
            print("ğŸ“Š RELACIÃ“N MODERADA POSITIVA")
        elif correlation > 0.3:
            print("ğŸ“ˆ RELACIÃ“N DÃ‰BIL POSITIVA")
        elif correlation < -0.7:
            print("ğŸ“‰ RELACIÃ“N MUY FUERTE NEGATIVA")
        elif correlation < -0.5:
            print("ğŸ“Š RELACIÃ“N MODERADA NEGATIVA")
        else:
            print("ğŸ”„ RELACIÃ“N MUY DÃ‰BIL O INEXISTENTE")
    else:
        print("âŒ CORRELACIÃ“N NO SIGNIFICATIVA ESTADÃSTICAMENTE")
    
    # RegresiÃ³n lineal
    X = precip.values.reshape(-1, 1)
    y = caudal.values
    model = LinearRegression().fit(X, y)
    r2 = r2_score(y, model.predict(X))
    
    print(f"ğŸ“Š COEFICIENTE DE DETERMINACIÃ“N (RÂ²): {r2:.3f}")
    print(f"ğŸ“ ECUACIÃ“N: Caudal = {model.coef_[0]:.4f} Ã— Precip + {model.intercept_:.2f}")
    
    # EstadÃ­sticas descriptivas
    print(f"\nğŸ“‹ ESTADÃSTICAS DESCRIPTIVAS:")
    print(f"   PrecipitaciÃ³n - Media: {precip.mean():.2f}, Desv: {precip.std():.2f}")
    print(f"   Caudal - Media: {caudal.mean():.2f}, Desv: {caudal.std():.2f}")
    
    return merged_data, correlation, r2, model

def create_visualizations(data, station_name, model):
    """Crear visualizaciones del anÃ¡lisis"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle(f'AnÃ¡lisis PrecipitaciÃ³n-Caudal: {station_name}', fontsize=16, fontweight='bold')
    
    precip = data['Precip_Total']
    caudal = data['Caudal_Prom']
    
    # 1. Diagrama de dispersiÃ³n
    axes[0, 0].scatter(precip, caudal, alpha=0.6, color='blue')
    axes[0, 0].set_xlabel('PrecipitaciÃ³n Total')
    axes[0, 0].set_ylabel('Caudal Promedio')
    axes[0, 0].set_title('Diagrama de DispersiÃ³n PrecipitaciÃ³n-Caudal')
    axes[0, 0].grid(True, alpha=0.3)
    
    # LÃ­nea de regresiÃ³n
    precip_sorted = np.sort(precip)
    caudal_pred = model.predict(precip_sorted.reshape(-1, 1))
    axes[0, 0].plot(precip_sorted, caudal_pred, 'r-', linewidth=2, 
                    label=f'RÂ² = {r2_score(data["Caudal_Prom"], model.predict(data["Precip_Total"].values.reshape(-1, 1))):.3f}')
    axes[0, 0].legend()
    
    # 2. Histogramas
    axes[0, 1].hist(precip, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 1].set_xlabel('PrecipitaciÃ³n Total')
    axes[0, 1].set_ylabel('Frecuencia')
    axes[0, 1].set_title('DistribuciÃ³n de PrecipitaciÃ³n')
    axes[0, 1].grid(True, alpha=0.3)
    
    axes[1, 0].hist(caudal, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[1, 0].set_xlabel('Caudal Promedio')
    axes[1, 0].set_ylabel('Frecuencia')
    axes[1, 0].set_title('DistribuciÃ³n de Caudal')
    axes[1, 0].grid(True, alpha=0.3)
    
    # 3. Serie temporal (si hay fechas)
    if len(data) > 1:
        axes[1, 1].plot(range(len(precip)), precip, 'b-', alpha=0.7, label='PrecipitaciÃ³n')
        ax2 = axes[1, 1].twinx()
        ax2.plot(range(len(caudal)), caudal, 'g-', alpha=0.7, label='Caudal')
        axes[1, 1].set_xlabel('Ãndice Temporal')
        axes[1, 1].set_ylabel('PrecipitaciÃ³n', color='b')
        ax2.set_ylabel('Caudal', color='g')
        axes[1, 1].set_title('Series Temporales')
        axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'analisis_{station_name.lower().replace(" ", "_")}.png', dpi=300, bbox_inches='tight')
    plt.show()

def main_correlation_analysis():
    """FunciÃ³n principal para anÃ¡lisis de correlaciÃ³n"""
    print("ğŸŒŠ ANÃLISIS DE CORRELACIÃ“N PRECIPITACIÃ“N-CAUDAL")
    print("="*60)
    
    # Cargar datos
    precip_papallacta, precip_quijos, caudal_papallacta, caudal_quijos = load_and_prepare_data()
    
    if precip_papallacta is None:
        return
    
    results = {}
    
    # AnÃ¡lisis Papallacta
    result_papallacta = analyze_correlation_station(
        precip_papallacta, caudal_papallacta, "Papallacta"
    )
    if result_papallacta:
        data_p, corr_p, r2_p, model_p = result_papallacta
        create_visualizations(data_p, "Papallacta", model_p)
        results['Papallacta'] = {'correlation': corr_p, 'r2': r2_p}
    
    # AnÃ¡lisis Quijos
    result_quijos = analyze_correlation_station(
        precip_quijos, caudal_quijos, "Quijos"
    )
    if result_quijos:
        data_q, corr_q, r2_q, model_q = result_quijos
        create_visualizations(data_q, "Quijos", model_q)
        results['Quijos'] = {'correlation': corr_q, 'r2': r2_q}
    
    # Resumen final
    print(f"\n{'='*60}")
    print("ğŸ“‹ RESUMEN GENERAL")
    print(f"{'='*60}")
    
    for station, metrics in results.items():
        print(f"\nğŸ“ {station}:")
        print(f"   CorrelaciÃ³n: {metrics['correlation']:.3f}")
        print(f"   RÂ²: {metrics['r2']:.3f}")
        
        if abs(metrics['correlation']) > 0.7:
            print("   ğŸ¯ RelaciÃ³n fuerte")
        elif abs(metrics['correlation']) > 0.5:
            print("   ğŸ“Š RelaciÃ³n moderada")
        elif abs(metrics['correlation']) > 0.3:
            print("   ğŸ“ˆ RelaciÃ³n dÃ©bil")
        else:
            print("   ğŸ”„ RelaciÃ³n muy dÃ©bil")
    
    return results

# Ejecutar anÃ¡lisis
if __name__ == "__main__":
    results = main_correlation_analysis()